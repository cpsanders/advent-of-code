{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506483"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 1.1\n",
    "\n",
    "df = pl.read_csv(Path(\"inputs/day_1.csv\"))\n",
    "left = df.select(\"left\").to_series().sort()\n",
    "right = df.select(\"right\").to_series().sort()\n",
    "(left - right).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>score</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>23126924</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌──────────┐\n",
       "│ score    │\n",
       "│ ---      │\n",
       "│ i64      │\n",
       "╞══════════╡\n",
       "│ 23126924 │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 1.2\n",
    "\n",
    "right_counts = df.group_by(\"right\").len()  # tells us how many times each unique value in right appears\n",
    "df.join(right_counts, left_on=\"left\", right_on=\"right\", how=\"left\").select(\n",
    "    [\n",
    "        pl.col(\"left\"),\n",
    "        pl.col(\"right\"),\n",
    "        pl.col(\"len\").fill_null(0).alias(\"count\"),\n",
    "    ]\n",
    ").with_columns(score=pl.col(\"left\") * pl.col(\"count\")).select(\"score\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 2.1\n",
    "\n",
    "rules_path = Path(\"inputs/day_2.txt\")\n",
    "lines = rules_path.read_text().splitlines()\n",
    "\n",
    "def is_safe(nums: list[int]) -> bool:\n",
    "    nums = np.array(nums)\n",
    "    diff = np.diff(nums)\n",
    "    in_range = np.all(np.abs(diff) >= 1) and np.all(np.abs(diff) <= 3)\n",
    "    consistent_sign = np.all(diff < 0) or np.all(diff > 0)\n",
    "    return in_range and consistent_sign\n",
    "\n",
    "num_safe = 0\n",
    "for line in lines:\n",
    "    report = list(map(int, line.split()))\n",
    "    diff = np.diff(report)\n",
    "    if is_safe(report):\n",
    "        num_safe += 1\n",
    "\n",
    "num_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 2.1 polars\n",
    "\n",
    "MAX_COLUMNS = 8\n",
    "rules_path = Path(\"inputs/day_2.txt\")\n",
    "schema = {f\"col{i}\": pl.Int64 for i in range(MAX_COLUMNS)}\n",
    "df = pl.read_csv(rules_path, separator=\" \", schema=schema, has_header=False)\n",
    "\n",
    "# partition based on which one should be increasing\n",
    "increasing_df = df.filter(pl.col(\"col2\") > pl.col(\"col1\"))\n",
    "decreasing_df = df.filter(pl.col(\"col2\") < pl.col(\"col1\"))\n",
    "\n",
    "# define the filter expressions for each case (increasing/decreasing)\n",
    "def get_filter_expression(increasing: bool, column_idx: int):\n",
    "    increment_expression = (\n",
    "        (pl.col(f\"col{column_idx}\") < pl.col(f\"col{column_idx+1}\"))\n",
    "        if increasing else (pl.col(f\"col{column_idx}\") > pl.col(f\"col{column_idx+1}\"))\n",
    "    )\n",
    "    return (\n",
    "        (abs(pl.col(f\"col{i}\").sub(pl.col(f\"col{i+1}\"))) >= 1)\n",
    "        & (abs(pl.col(f\"col{i}\").sub(pl.col(f\"col{i+1}\"))) <= 3)\n",
    "        & increment_expression\n",
    "        | (pl.col(f\"col{i}\").is_null())\n",
    "        | (pl.col(f\"col{i+1}\").is_null())\n",
    "    )\n",
    "\n",
    "# filter dataframes based on condition\n",
    "for i in range(len(df.columns) - 1):\n",
    "    increasing_df = increasing_df.filter(get_filter_expression(True, i))\n",
    "    decreasing_df = decreasing_df.filter(get_filter_expression(False, i))\n",
    "\n",
    "len(increasing_df) + len(decreasing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 2.2\n",
    "\n",
    "rules_path = Path(\"inputs/day_2.txt\")\n",
    "lines = rules_path.read_text().splitlines()\n",
    "\n",
    "num_safe = 0\n",
    "for line in lines:\n",
    "    report = list(map(int, line.split()))\n",
    "    if is_safe(report):\n",
    "        num_safe += 1\n",
    "    else:\n",
    "        for i in range(len(report)):\n",
    "            sub_report = report[:i] + report[i+1:]\n",
    "            if is_safe(sub_report):\n",
    "                num_safe += 1\n",
    "                break\n",
    "\n",
    "num_safe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142318368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 3.1\n",
    "\n",
    "import re\n",
    "\n",
    "rules_path = Path(\"inputs/day3.txt\")\n",
    "with Path(rules_path).open(\"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "pattern = r\"mul\\(\\s*([+-]?\\d+)\\s*,\\s*([+-]?\\d+)\\s*\\)\"\n",
    "matches = re.findall(pattern, content)\n",
    "mult_sum = sum([int(match[0]) * int(match[1]) for match in matches])\n",
    "mult_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62328317"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 3.2\n",
    "\n",
    "import re\n",
    "\n",
    "rules_path = Path(\"inputs/day3.txt\")\n",
    "with Path(rules_path).open(\"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "pattern = r\"mul\\(\\s*([+-]?\\d+)\\s*,\\s*([+-]?\\d+)\\s*\\)|(do\\(\\)|don't\\(\\))\"\n",
    "matches = re.findall(pattern, content)\n",
    "\n",
    "dont_str = \"don't()\"\n",
    "do_str = \"do()\"\n",
    "do = True\n",
    "mult_sum = 0\n",
    "\n",
    "for group in matches:\n",
    "    if dont_str in group:\n",
    "        do = False\n",
    "\n",
    "    if do_str in group:\n",
    "        do = True\n",
    "\n",
    "    if do and group[0] != \"\" and group[1] != \"\":\n",
    "        mult_sum += int(group[0]) * int(group[1])\n",
    "\n",
    "mult_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 4.1\n",
    "\n",
    "contents = np.array([list(line.strip()) for line in list(Path(\"inputs/day_4.txt\").read_text().splitlines())])\n",
    "\n",
    "target = \"XMAS\"\n",
    "\n",
    "pad = len(target) - 1\n",
    "contents = np.pad(contents, pad, mode=\"constant\", constant_values=\"-\")\n",
    "\n",
    "window_length = 2 * (len(target)) - 1\n",
    "\n",
    "directions = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1)]\n",
    "\n",
    "target_matches = 0\n",
    "for row_idx in range(contents.shape[0]):\n",
    "    for column_idx in range(contents.shape[1]):\n",
    "        # find all possible starting locations of the target string\n",
    "        if contents[row_idx][column_idx] == target[0]:\n",
    "            # get the window for the possible target string\n",
    "            columns = np.arange(column_idx - len(target) + 1, column_idx + len(target))\n",
    "            column_indices = np.repeat(columns, window_length).reshape((window_length, window_length)).T\n",
    "            rows = np.arange(row_idx - len(target) + 1, row_idx + len(target))\n",
    "            row_indices = np.tile(rows, window_length).reshape((window_length, window_length)).T\n",
    "            window = contents[row_indices, column_indices]\n",
    "\n",
    "            # determine the number of times the target string occurs in the window\n",
    "            center = len(window) // 2\n",
    "            for row_direction, column_direction in directions:\n",
    "                char_matches = 0\n",
    "                for i in range(len(target)):\n",
    "                    r, c = center + row_direction * i, center + column_direction * i\n",
    "                    if window[r, c] != target[i]:\n",
    "                        break\n",
    "                    else:\n",
    "                        char_matches += 1\n",
    "\n",
    "                if char_matches == len(target):\n",
    "                    target_matches += 1\n",
    "\n",
    "target_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# day 4.2\n",
    "\n",
    "contents = np.array([list(line.strip()) for line in list(Path(\"inputs/day4.txt\").read_text().splitlines())])\n",
    "\n",
    "target = \"MAS\"\n",
    "rev_target = target[::-1]\n",
    "x_mas_matches = 0\n",
    "for row_index in range(1, contents.shape[0] - 1):\n",
    "    for column_index in range(1, contents.shape[1] - 1):\n",
    "        if contents[row_index, column_index] == target[len(target) // 2]:\n",
    "            # get the window indices for the possible target string\n",
    "            idx_past_center = len(target[:len(target) // 2])\n",
    "            column_indices = np.arange(column_index - idx_past_center, column_index + idx_past_center + 1)\n",
    "            row_indices = np.arange(row_index - idx_past_center, row_index + idx_past_center + 1)\n",
    "\n",
    "            diag1 = \"\".join(contents[row_indices, column_indices])\n",
    "            diag2 = \"\".join(contents[row_indices[::-1], column_indices])\n",
    "            if (diag1 == target or diag1 == rev_target) and (diag2 == target or diag2 == rev_target):\n",
    "                x_mas_matches += 1\n",
    "\n",
    "x_mas_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally-correct sum: 5948\n",
      "Originally-incorrect sum: 3062\n"
     ]
    }
   ],
   "source": [
    "# day 5.1 and 5.2\n",
    "rules_path = Path(\"inputs/day5_rules.txt\")\n",
    "updates_path = Path(\"inputs/day5_updates.txt\")\n",
    "rules_arr = pl.read_csv(rules_path, separator=\"|\").to_numpy()\n",
    "\n",
    "# create hash map of rules\n",
    "rules_hash: dict[int, list[int]] = {}\n",
    "for rule in rules_arr:\n",
    "    if rules_hash.get(rule[0]) is None:\n",
    "        rules_hash[int(rule[0])] = [int(rule[1])]\n",
    "    else:\n",
    "        rules_hash[rule[0]].append(int(rule[1]))\n",
    "\n",
    "valid_middle_page_sum = 0\n",
    "sorted_middle_page_sum = 0\n",
    "with updates_path.open(\"r\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        page_update = list(map(int, line.strip().split(\",\")))\n",
    "        update_is_valid = True\n",
    "\n",
    "        j = 1\n",
    "        while j < len(page_update):\n",
    "            page_rules = rules_hash.get(page_update[j])\n",
    "            if page_rules is None:\n",
    "                j += 1\n",
    "                continue\n",
    "\n",
    "            for page_rule in page_rules:\n",
    "                if page_rule in page_update[:j]:\n",
    "                    update_is_valid = False\n",
    "                    move_page = page_update.pop(j)\n",
    "                    page_update.insert(j-1, move_page)\n",
    "                    j = 0\n",
    "                    break\n",
    "            j += 1\n",
    "\n",
    "        if update_is_valid:\n",
    "            valid_middle_page_sum += page_update[len(page_update) // 2]\n",
    "        else:\n",
    "            sorted_middle_page_sum += page_update[len(page_update) // 2]\n",
    "\n",
    "print(f\"Originally-correct sum: {valid_middle_page_sum}\")\n",
    "print(f\"Originally-incorrect sum: {sorted_middle_page_sum}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
